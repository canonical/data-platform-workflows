# Copyright 2023 Canonical Ltd.
# See LICENSE file for licensing details.

# Usage documentation: integration_test_charm.md

on:
  workflow_call:
    inputs:
      artifact-prefix:
        description: |
          Prefix for charm package GitHub artifact(s)

          Use canonical/data-platform-workflows build_charm.yaml to build the charm(s)
        required: true
        type: string
      architecture:
        # Keep description synchronized with "Parse architecture input" step
        description: |
          Processor architecture
          
          Must be one of "amd64", "arm64"
        default: amd64
        type: string
      cloud:
        # Keep description synchronized with "Parse cloud input" step
        description: |
          Juju cloud

          Must be one of: "lxd", "microk8s"

          https://juju.is/docs/olm/cloud
        required: true
        type: string
      microk8s-snap-channel:
        description: |
          microk8s snap channel

          Required if `cloud` input is "microk8s"
        required: false
        type: string
      lxd-snap-channel:
        description: LXD snap channel
        default: latest/stable
        type: string
      juju-agent-version:
        description: Juju agent version
        required: false
        type: string
      juju-snap-channel:
        description: |
          Juju CLI snap channel

          Required if `juju-agent-version` input is not passed
        required: false
        type: string
      libjuju-version-constraint:
        description: |
          Poetry-compatible python-libjuju version constraint (e.g. "^1.2.3", ">= 1.2, < 1.5")
          https://python-poetry.org/docs/dependency-specification/#version-constraints

          Overrides python-libjuju version constraint in Poetry `integration` dependency group

          Each version of python-libjuju is only compatible with one major Juju version

          Recommendation: With Poetry, pin python-libjuju for the latest major Juju version.
          To test older major Juju versions, override the version constraint with this input.
        required: false
        type: string
      _beta_allure_report:
        description: |
          (BETA) Enable Allure Report
          
          Subject to breaking changes without major version bump.
          Not currently a public interface—only for testing
          
          If this workflow is called with a matrix, this value can only be `true` for one
          combination in the matrix
        default: false
        type: boolean
    secrets:
      integration-test:
        description: |
          Secrets needed in integration tests

          Passed to tests with `SECRETS_FROM_GITHUB` environment variable

          Use a string representation of a Python dict[str, str] built from multiple GitHub secrets
          Do NOT put the string into a single GitHub secret—build the string from multiple GitHub secrets so that GitHub is more likely to redact the secrets in GitHub Actions logs.

          Python code to verify the string format:
          ```
          import ast
          secrets = ast.literal_eval("")
          assert isinstance(secrets, dict)
          for key, value in secrets.items():
              assert isinstance(key, str) and isinstance(value, str)
          ```
        required: false

jobs:
  collect-integration-tests:
    # In nested CI calls (e.g. release.yaml calls ci.yaml calls this workflow) the job name in
    # ci.yaml will not show up on the GitHub Actions sidebar.
    # If this workflow is called with a matrix (e.g. to test multiple juju versions), the ci.yaml
    # job name containing the Juju version will be lost.
    # So, we add the Juju version & architecture to one of the first jobs in this workflow.
    # (In the UI, when this workflow is called with a matrix, GitHub will separate each matrix
    # combination and preserve job ordering within a matrix combination.)
    name: ${{ inputs.juju-agent-version || inputs.juju-snap-channel }} | ${{ inputs.architecture }} | Collect integration test groups
    # Only run arm64 integration tests on `schedule`
    # Temporary solution to decrease costs (of GitHub hosted arm64 runners) while IS hosted arm64 runners are unstable.
    # Context: https://chat.canonical.com/canonical/channels/actions-incident
    # TODO: remove (since we're using Azure-hosted runners now)
    if: ${{ inputs.architecture == 'amd64' || (inputs.architecture == 'arm64' && github.event_name == 'schedule' && github.run_attempt == '1') }}
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - name: Parse architecture input
        id: parse-architecture
        shell: python
        # Keep synchronized with inputs.architecture description
        run: |
          import json
          import os
          
          DEFAULT_RUNNERS = {
              "amd64": "ubuntu-latest",
              "arm64": ["self-hosted", "data-platform", "ubuntu", "ARM64", "4cpu16ram"],
          }
          ARCHITECTURE = "${{ inputs.architecture }}"
          try:
              default_runner = DEFAULT_RUNNERS[ARCHITECTURE]
          except KeyError:
              raise ValueError(f"`architecture` input not recognized: {ARCHITECTURE}")
          output = f"default_runner={json.dumps(default_runner)}"
          print(output)
          with open(os.environ["GITHUB_OUTPUT"], "a") as file:
              file.write(output)
      - name: Checkout
        uses: actions/checkout@v4
      - name: Install tox & poetry
        run: |
          pipx install tox
          pipx install poetry
      - name: Select test stability level
        id: select-test-stability
        shell: python
        run: |
          import os

          if "${{ github.event_name }}" == "schedule":
              print("Running unstable and stable tests")
              output = "mark_expression="
          else:
              print("Skipping unstable tests")
              output = "mark_expression=not unstable"

          with open(os.environ["GITHUB_OUTPUT"], "a") as file:
              file.write(output)
      - name: (beta) Get Allure collection option
        if: ${{ inputs._beta_allure_report }}
        id: allure-collection-option
        # TODO future improvement: check if allure-pytest installed instead
        shell: python
        run: |
          import os

          output = "option=--allure-collection-dir=allure-collection-default-results"

          with open(os.environ["GITHUB_OUTPUT"], "a") as file:
              file.write(output)
      - name: Collect test groups
        id: collect-groups
        run: tox run -e integration -- tests/integration -m '${{ steps.select-test-stability.outputs.mark_expression }}' --collect-groups ${{ steps.allure-collection-option.outputs.option }}
      - name: (beta) Upload Allure collection results
        # Default test results in case the integration tests time out or runner set up fails
        # (So that Allure report will show "unknown"/"failed" test result, instead of omitting the test)
        if: ${{ inputs._beta_allure_report && github.event_name == 'schedule' && github.run_attempt == '1' }}
        uses: actions/upload-artifact@v4
        with:
          # TODO future improvement: ensure artifact name is unique (if called with a matrix that changes inputs)
          name: allure-collection-default-results-integration-test-charm
          path: allure-collection-default-results/
          if-no-files-found: error
    outputs:
      groups: ${{ steps.collect-groups.outputs.groups }}
      default_runner: ${{ steps.parse-architecture.outputs.default_runner }}

  integration-test:
    strategy:
      fail-fast: false
      matrix:
        groups: ${{ fromJSON(needs.collect-integration-tests.outputs.groups) }}
    name: ${{ matrix.groups.job_name }}
    needs:
      - collect-integration-tests
    runs-on: ${{ matrix.groups.runner || fromJSON(needs.collect-integration-tests.outputs.default_runner) }}
    timeout-minutes: 216  # Sum of steps `timeout-minutes` + 5
    steps:
      - name: (Data Platform hosted) Write job name to file
        # Data Platform hosted
        # `inputs.architecture == 'arm64' && matrix.groups.runner == null` means Data Platform hosted (default runner)
        if: ${{ matrix.groups.data_platform_hosted || (inputs.architecture == 'arm64' && matrix.groups.runner == null) }}
        # Used to show job name in GitHub Actions annotation
        # (https://docs.github.com/en/actions/using-workflows/workflow-commands-for-github-actions#setting-a-notice-message)
        # if spot instance evicted by Azure
        run: |
          mkdir ~/dpw/
          echo '${{ matrix.groups.job_name }}' > ~/dpw/job_name
      - name: (GitHub hosted) Free up disk space
        timeout-minutes: 1
        # If not (IS hosted or Data Platform hosted)
        # `inputs.architecture == 'arm64' && matrix.groups.runner == null` means Data Platform hosted (default runner)
        if: ${{ !(matrix.groups.is_hosted || matrix.groups.data_platform_hosted || (inputs.architecture == 'arm64' && matrix.groups.runner == null)) }}
        run: |
          printf '\nDisk usage before cleanup\n'
          df --human-readable
          # Based on https://github.com/actions/runner-images/issues/2840#issuecomment-790492173
          rm -r /usr/share/dotnet
          rm -r /opt/hostedtoolcache/
          printf '\nDisk usage after cleanup\n'
          df --human-readable
      - name: (self hosted) Disk usage
        timeout-minutes: 1
        # If IS hosted or Data Platform hosted
        # `inputs.architecture == 'arm64' && matrix.groups.runner == null` means Data Platform hosted (default runner)
        if: ${{ matrix.groups.is_hosted || matrix.groups.data_platform_hosted || (inputs.architecture == 'arm64' && matrix.groups.runner == null) }}
        run: df --human-readable
      - name: (self hosted) Install pipx
        timeout-minutes: 3
        if: ${{ matrix.groups.is_hosted }}
        run: |
          sudo apt-get update
          # python3-pip recommends build-essential—a relatively large package we don't need
          sudo apt-get install python3-pip python3-venv -y --no-install-recommends
          python3 -m pip install --user pipx
          python3 -m pipx ensurepath
          echo "$HOME/.local/bin" >> "$GITHUB_PATH"
      - name: Get workflow version
        timeout-minutes: 2
        id: workflow-version
        uses: canonical/get-workflow-version-action@v1
        with:
          repository-name: canonical/data-platform-workflows
          file-name: integration_test_charm.yaml
          github-token: ${{ secrets.GITHUB_TOKEN }}
      - name: Install CLI
        timeout-minutes: 2
        run: pipx install git+https://github.com/canonical/data-platform-workflows@'${{ steps.workflow-version.outputs.sha }}'#subdirectory=python/cli
      - name: Redact secrets from log
        timeout-minutes: 1
        run: redact-secrets
        env:
          SECRETS: ${{ secrets.integration-test }}
      - name: Parse cloud input
        timeout-minutes: 1
        id: parse-cloud
        shell: python
        # Keep synchronized with inputs.cloud description
        run: |
          import json
          import os

          CLOUD = "${{ inputs.cloud }}"
          is_hosted = json.loads("${{ matrix.groups.is_hosted }}")
          assert isinstance(is_hosted, bool)
          if CLOUD == "lxd":
              group = "lxd"
          elif CLOUD == "microk8s":
              if is_hosted:
                  raise ValueError("microk8s not supported on IS hosted runners")
              SNAP_CHANNEL = "${{ inputs.microk8s-snap-channel }}"
              assert (
                  SNAP_CHANNEL != ""
              ), '`microk8s-snap-channel` input required if `cloud` is "microk8s"'
              assert "strict" in SNAP_CHANNEL.lower(), "Only strict microk8s snap supported"
              group = "snap_microk8s"
          else:
              raise ValueError(f"`cloud` input not recognized: {CLOUD}")
          output = f"group={group}"
          print(output)
          with open(os.environ["GITHUB_OUTPUT"], "a") as file:
              file.write(output)
      - name: Parse Juju agent version & snap channel
        timeout-minutes: 1
        id: parse-versions
        shell: python
        run: |
          import os

          AGENT_VERSION = "${{ inputs.juju-agent-version }}"
          snap_channel = "${{ inputs.juju-snap-channel }}"
          if not snap_channel:
              if AGENT_VERSION:
                  major, minor, patch = AGENT_VERSION.split(".")
                  snap_channel = f"{major}.{minor}/stable"
              else:
                  raise Exception(
                      "`juju-snap-channel` required if `juju-agent-version` is not passed"
                  )

          output = "agent_bootstrap_option="
          if AGENT_VERSION:
              output += f"--agent-version={AGENT_VERSION}"
          output += f"\nsnap_channel={snap_channel}"
          # GitHub artifact name cannot contain "/"
          output += f'\nsnap_channel_for_artifact={snap_channel.replace("/", "-")}'

          print(output)
          with open(os.environ["GITHUB_OUTPUT"], "a") as file:
              file.write(output)
      - name: Checkout
        timeout-minutes: 3
        uses: actions/checkout@v4
      - name: Set up environment
        timeout-minutes: 5
        run: |
          # `--classic` applies to juju 2 snap; ignored for juju 3 snap
          sudo snap install juju --classic --channel='${{ steps.parse-versions.outputs.snap_channel }}'
      - name: Set up lxd
        timeout-minutes: 5
        if: ${{ inputs.cloud == 'lxd' }}
        run: |
          sudo snap refresh lxd --channel='${{ inputs.lxd-snap-channel }}'
          sudo adduser "$USER" '${{ steps.parse-cloud.outputs.group }}'
          # `newgrp` does not work in GitHub Actions; use `sg` instead
          sg '${{ steps.parse-cloud.outputs.group }}' -c "lxd waitready"
          sg '${{ steps.parse-cloud.outputs.group }}' -c "lxd init --auto"
          sg '${{ steps.parse-cloud.outputs.group }}' -c "lxc network set lxdbr0 ipv6.address none"
          sudo iptables -F FORWARD
          sudo iptables -P FORWARD ACCEPT
      - name: Set up microk8s
        timeout-minutes: 15
        if: ${{ inputs.cloud == 'microk8s' }}
        run: |
          sudo apt-get update
          sudo apt-get install retry -y
          sudo snap install microk8s --channel='${{ inputs.microk8s-snap-channel }}'
          sudo adduser "$USER" '${{ steps.parse-cloud.outputs.group }}'
          # `newgrp` does not work in GitHub Actions; use `sg` instead
          sg '${{ steps.parse-cloud.outputs.group }}' -c "microk8s status --wait-ready"
          sg '${{ steps.parse-cloud.outputs.group }}' -c "retry --times 3 --delay 5 -- sudo microk8s enable dns"
          sg '${{ steps.parse-cloud.outputs.group }}' -c "microk8s status --wait-ready"
          sg '${{ steps.parse-cloud.outputs.group }}' -c "microk8s.kubectl rollout status --namespace kube-system --watch --timeout=5m deployments/coredns"
          sg '${{ steps.parse-cloud.outputs.group }}' -c "retry --times 3 --delay 5 -- sudo microk8s enable hostpath-storage"
          sg '${{ steps.parse-cloud.outputs.group }}' -c "microk8s.kubectl rollout status --namespace kube-system --watch --timeout=5m deployments/hostpath-provisioner"
          mkdir ~/.kube/
          # Used by lightkube and kubernetes (Python package)
          sg '${{ steps.parse-cloud.outputs.group }}' -c "microk8s config > ~/.kube/config"
      - timeout-minutes: 1
        run: snap list
      - name: Set up environment
        timeout-minutes: 25
        run: |
          mkdir -p ~/.local/share/juju  # Workaround for juju 3 strict snap
          sg '${{ steps.parse-cloud.outputs.group }}' -c "juju bootstrap '${{ inputs.cloud }}' '${{ steps.parse-versions.outputs.agent_bootstrap_option }}'"
          juju model-defaults logging-config='<root>=INFO; unit=DEBUG'
          juju add-model test
          # Unable to set constraint on all models because of Juju bug:
          # https://bugs.launchpad.net/juju/+bug/2065050
          juju set-model-constraints arch='${{ inputs.architecture }}'
          pipx install tox
          pipx install poetry
      - name: Update python-libjuju version
        timeout-minutes: 3
        if: ${{ inputs.libjuju-version-constraint }}
        run: poetry add --lock --group integration juju@'${{ inputs.libjuju-version-constraint }}'
      - name: Download packed charm(s)
        timeout-minutes: 5
        uses: actions/download-artifact@v4
        with:
          pattern: ${{ inputs.artifact-prefix }}-*
          merge-multiple: true
      - name: Select test stability level
        timeout-minutes: 1
        id: select-test-stability
        shell: python
        run: |
          import os

          if "${{ github.event_name }}" == "schedule":
              print("Running unstable and stable tests")
              output = "mark_expression="
          else:
              print("Skipping unstable tests")
              output = "mark_expression=not unstable"

          with open(os.environ["GITHUB_OUTPUT"], "a") as file:
              file.write(output)
      - name: (beta) Get Allure option
        timeout-minutes: 1
        if: ${{ inputs._beta_allure_report }}
        id: allure-option
        # TODO future improvement: check if allure-pytest installed instead
        shell: python
        run: |
          import os

          output = "option=--alluredir=allure-results"

          with open(os.environ["GITHUB_OUTPUT"], "a") as file:
              file.write(output)
      - name: Run integration tests
        timeout-minutes: 120
        id: tests
        run: sg '${{ steps.parse-cloud.outputs.group }}' -c "tox run -e integration -- '${{ matrix.groups.path_to_test_file }}' --group='${{ matrix.groups.group_id }}' -m '${{ steps.select-test-stability.outputs.mark_expression }}' --model test ${{ steps.allure-option.outputs.option }}"
        env:
          SECRETS_FROM_GITHUB: ${{ secrets.integration-test }}
      - name: (beta) Upload Allure results
        timeout-minutes: 3
        if: ${{ (success() || (failure() && steps.tests.outcome == 'failure')) && inputs._beta_allure_report && github.event_name == 'schedule' && github.run_attempt == '1' }}
        uses: actions/upload-artifact@v4
        with:
          name: allure-results-integration-test-charm-${{ inputs.cloud }}-juju-${{ inputs.juju-agent-version || steps.parse-versions.outputs.snap_channel_for_artifact }}-${{ inputs.architecture }}-${{ matrix.groups.artifact_group_id }}
          path: allure-results/
          if-no-files-found: error
      - name: Select model
        timeout-minutes: 1
        if: ${{ success() || (failure() && steps.tests.outcome == 'failure') }}
        run: |
          juju switch test
          mkdir ~/logs/
      - name: juju status
        timeout-minutes: 1
        if: ${{ success() || (failure() && steps.tests.outcome == 'failure') }}
        run: juju status --color --relations | tee ~/logs/juju-status.txt
      - name: juju debug-log
        timeout-minutes: 3
        if: ${{ success() || (failure() && steps.tests.outcome == 'failure') }}
        # TODO future improvement: show models/ logs in juju-debug-log.txt to match `juju debug-log`
        run: |
          if [[ '${{ inputs.cloud }}' == 'lxd' ]]
          then
            mkdir ~/logs/models/
            juju scp --model controller 0:/var/log/juju/models/* ~/logs/models/
            juju scp --model controller 0:/var/log/juju/logsink.log ~/logs/controller-logsink.log
            convert-logsink-to-debug-log ~/logs/controller-logsink.log ~/logs/juju-debug-log.txt
            cat ~/logs/juju-debug-log.txt
          else
            juju debug-log --color --replay --no-tail | tee ~/logs/juju-debug-log.txt
          fi
      - name: Upload logs
        timeout-minutes: 5
        if: ${{ success() || (failure() && steps.tests.outcome == 'failure') }}
        uses: actions/upload-artifact@v4
        with:
          name: logs-intergration-test-charm-${{ inputs.cloud }}-juju-${{ inputs.juju-agent-version || steps.parse-versions.outputs.snap_channel_for_artifact }}-${{ inputs.architecture }}-${{ matrix.groups.artifact_group_id }}
          path: ~/logs/
          if-no-files-found: error
      - name: Disk usage
        timeout-minutes: 1
        if: ${{ success() || (failure() && steps.tests.outcome == 'failure') }}
        run: df --human-readable
    outputs:
      juju-snap-channel-for-artifact: ${{ steps.parse-versions.outputs.snap_channel_for_artifact }}

  allure-report:
    # TODO future improvement: use concurrency group for job
    name: (beta) Publish Allure report
    if: ${{ !cancelled() && inputs._beta_allure_report && github.event_name == 'schedule' && github.run_attempt == '1'}}
    needs:
      - integration-test
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - name: Get workflow version
        id: workflow-version
        uses: canonical/get-workflow-version-action@v1
        with:
          repository-name: canonical/data-platform-workflows
          file-name: integration_test_charm.yaml
          github-token: ${{ secrets.GITHUB_TOKEN }}
      - name: Install CLI
        run: pipx install git+https://github.com/canonical/data-platform-workflows@'${{ steps.workflow-version.outputs.sha }}'#subdirectory=python/cli
      - name: Download Allure
        # Following instructions from https://allurereport.org/docs/gettingstarted-installation/#install-via-the-system-package-manager-for-linux
        run: gh release download --repo allure-framework/allure2 --pattern 'allure_*.deb'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      - name: Install Allure
        run: |
          sudo apt-get update
          sudo apt-get install ./allure_*.deb -y
      # For first run, manually create branch with no history
      # (e.g.
      # git checkout --orphan gh-pages-beta
      # git rm -rf .
      # touch .nojekyll
      # git add .nojekyll
      # git commit -m "Initial commit"
      # git push origin gh-pages-beta
      # )
      - name: Checkout GitHub pages branch
        uses: actions/checkout@v4
        with:
          ref: gh-pages-beta
          path: repo/
      - name: Download default test collection results
        # Default test results in case the integration tests time out or runner set up fails
        # (So that Allure report will show "unknown"/"failed" test result, instead of omitting the test)
        uses: actions/download-artifact@v4
        with:
          path: allure-collection-default-results/
          name: allure-collection-default-results-integration-test-charm
      - name: Download test results
        uses: actions/download-artifact@v4
        with:
          path: allure-results/
          pattern: allure-results-integration-test-charm-${{ inputs.cloud }}-juju-${{ inputs.juju-agent-version || needs.integration-test.outputs.juju-snap-channel-for-artifact }}-${{ inputs.architecture }}-*
          merge-multiple: true
      - name: Combine Allure default results & actual results
        # For every test: if actual result available, use that. Otherwise, use default result
        # So that, if actual result not available, Allure report will show "unknown"/"failed" test result
        # instead of omitting the test
        run: allure-add-default-for-missing-results --allure-results-dir=allure-results --allure-collection-default-results-dir=allure-collection-default-results
      - name: Load test report history
        run: |
          if [[ -d repo/_latest/history/ ]]
          then
            echo 'Loading history'
            cp -r repo/_latest/history/ allure-results/
          fi
      - name: Create executor.json
        shell: python
        run: |
          # Reverse engineered from https://github.com/simple-elf/allure-report-action/blob/eca283b643d577c69b8e4f048dd6cd8eb8457cfd/entrypoint.sh
          import json

          DATA = {
              "name": "GitHub Actions",
              "type": "github",
              "buildOrder": ${{ github.run_number }},  # TODO future improvement: use run ID
              "buildName": "Run ${{ github.run_id }}",
              "buildUrl": "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}",
              "reportUrl": "../${{ github.run_number }}/",
          }
          with open("allure-results/executor.json", "w") as file:
              json.dump(DATA, file)
      - name: Generate Allure report
        run: allure generate
      - name: Create index.html
        shell: python
        run: |
          DATA = f"""<!DOCTYPE html>
          <meta charset="utf-8">
          <meta http-equiv="cache-control" content="no-cache">
          <meta http-equiv="refresh" content="0; url=${{ github.run_number }}">
          """
          with open("repo/index.html", "w") as file:
              file.write(DATA)
      - name: Update GitHub pages branch
        working-directory: repo/
        # TODO future improvement: commit message
        run: |
          mkdir '${{ github.run_number }}'
          rm -f _latest
          ln -s '${{ github.run_number }}' _latest
          cp -r ../allure-report/. _latest/
          git add .
          git config user.name "GitHub Actions"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git commit -m "Allure report #${{ github.run_number }}"
          # Uses token set in checkout step
          git push origin gh-pages-beta
